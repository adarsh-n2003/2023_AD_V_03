{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o4fRpLz9DX7l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Constants\n",
        "IMAGE_SIZE = (150, 150)  # Change according to your dataset\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAjmOxHwIoLr"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive (if using Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bA8q1y5FHkxQ"
      },
      "outputs": [],
      "source": [
        "# Path to the dataset zip file\n",
        "zip_path = '/content/drive/MyDrive/Water Treatment Dataset.zip'\n",
        "\n",
        "import zipfile\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')  # Extract to /content directory in Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5UzO8pZcEHTl",
        "outputId": "b1698b3b-9024-4d84-ea0a-2c252145472c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Water directory exists: True\n",
            "Not Water directory exists: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Path to the dataset\n",
        "data_path = '/content/Dataset'\n",
        "\n",
        "# Path to the \"water\" and \"not_water\" directories\n",
        "water_path = os.path.join(data_path, 'Water')\n",
        "not_water_path = os.path.join(data_path, 'Not Water')\n",
        "\n",
        "# Check if the directories exist\n",
        "print(\"Water directory exists:\", os.path.isdir(water_path))\n",
        "print(\"Not Water directory exists:\", os.path.isdir(not_water_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RsJmBNncDldx"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Load the list of filenames from the directories\n",
        "water_filenames = glob.glob(os.path.join(water_path, '*.*'))  # Adjust the file extension if needed\n",
        "not_water_filenames = glob.glob(os.path.join(not_water_path, '*.*'))\n",
        "\n",
        "# Combine filenames and create labels\n",
        "filenames = water_filenames + not_water_filenames\n",
        "labels = ['water'] * len(water_filenames) + ['not_water'] * len(not_water_filenames)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_filenames, test_filenames, train_labels, test_labels = train_test_split(\n",
        "    filenames, labels, test_size=0.2, random_state=42, stratify=labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fXinxEGADlbW",
        "outputId": "f0ba1fb4-9bbc-4da6-ec8e-8f226511d8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 24580 images belonging to 2 classes.\n",
            "Found 6144 images belonging to 2 classes.\n",
            "Found 30724 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Data generators for training and testing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Configure data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Dj9q8eE0DlY1"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "knuvfrEgDlVw",
        "outputId": "8b8c1002-a5c8-45f6-a716-e7e121dcfc29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "769/769 [==============================] - 1296s 2s/step - loss: 0.3643 - accuracy: 0.8397 - val_loss: 0.3447 - val_accuracy: 0.8379\n",
            "Epoch 2/20\n",
            "769/769 [==============================] - 1228s 2s/step - loss: 0.2719 - accuracy: 0.8858 - val_loss: 0.3534 - val_accuracy: 0.8452\n",
            "Epoch 3/20\n",
            "769/769 [==============================] - 1223s 2s/step - loss: 0.2165 - accuracy: 0.9105 - val_loss: 0.2975 - val_accuracy: 0.8812\n",
            "Epoch 4/20\n",
            "769/769 [==============================] - 1205s 2s/step - loss: 0.1709 - accuracy: 0.9298 - val_loss: 0.3425 - val_accuracy: 0.8503\n",
            "Epoch 5/20\n",
            "769/769 [==============================] - 1241s 2s/step - loss: 0.1434 - accuracy: 0.9419 - val_loss: 0.3755 - val_accuracy: 0.8493\n",
            "Epoch 6/20\n",
            "769/769 [==============================] - 1211s 2s/step - loss: 0.1163 - accuracy: 0.9531 - val_loss: 0.3982 - val_accuracy: 0.8472\n",
            "961/961 [==============================] - 441s 459ms/step - loss: 0.2026 - accuracy: 0.9200\n",
            "Test accuracy: 91.99973940849304 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Early stopping to avoid overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
        "print('Test accuracy:', test_acc * 100, '%')\n",
        "\n",
        "# Save the model\n",
        "model.save('water_detection_model.h5')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}